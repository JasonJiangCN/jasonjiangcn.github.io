<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <title>Python爬虫笔记 | Jason&#39;s Blog</title>
  <meta name="description" content="你皮任你皮，把你当瓜皮" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <link rel="stylesheet" type="text/css" href="/css/screen.css" />
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />

  <meta name="generator" content="Jason's Blog">

  
  
  

  
</head>


<body class="post-template">

  <header class="site-head"  style="background-image: url(/personal_img/maxresdefault.jpg)" >
    <div class="vertical">
        <div class="site-head-content inner">
             <a class="blog-logo" href="/"><img src="/personal_img/Terminal-icon.png" alt="Blog Logo"/></a> 
            <h1 class="blog-title">Jason's Blog</h1>
            <h2 class="blog-description">你皮任你皮，把你当瓜皮</h2>
        </div>
    </div>
</header>
  

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2017-05-27T12:19:32.000Z" itemprop="datePublished">
          2017-05-27
      </time>
    
</span>
    <h1 class="post-title">Python爬虫笔记</h1>
    <section class="post-content">
      <h1 id="简单爬虫架构"><a href="#简单爬虫架构" class="headerlink" title="简单爬虫架构"></a>简单爬虫架构</h1><p>爬虫调度端 —&gt; url管理器 —&gt;网页下载器 —&gt; 网页解析器 —&gt; 有价值的数据</p>
<p>只要有相关的url 中间的爬虫架构会一直运行下去</p>
<h2 id="运行流程"><a href="#运行流程" class="headerlink" title="运行流程"></a>运行流程</h2><p><img src="https://image.ibb.co/hRpHav/IMG_0005.png" alt=""></p>
<h1 id="URL-管理器"><a href="#URL-管理器" class="headerlink" title="URL 管理器"></a>URL 管理器</h1><p>防止重复抓取和循环抓取</p>
<h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><p>第一种：将待爬取的放在内存里</p>
<p>e.g.. 在py中放在两个set里</p>
<p>第二种：放在关系数据库里</p>
<p>urls(url,is_crawled)</p>
<p>第三种：缓存数据库</p>
<p>两个set 已爬取和待爬去</p>
<h1 id="网页下载器"><a href="#网页下载器" class="headerlink" title="网页下载器"></a>网页下载器</h1><p>将url对应的网页下载下来</p>
<p>以html的格式存到本地</p>
<h2 id="python的下载器"><a href="#python的下载器" class="headerlink" title="python的下载器"></a>python的下载器</h2><ol>
<li>urllib2 py官方的</li>
<li>requests 第三方 更强大</li>
</ol>
<h2 id="urllib2-的使用"><a href="#urllib2-的使用" class="headerlink" title="urllib2 的使用"></a>urllib2 的使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="comment">#直接请求</span></div><div class="line">response = urllib2.urlopen(<span class="string">"http://www.baidu.com"</span>)</div><div class="line"><span class="comment">#获取状态码 如果为200则成功</span></div><div class="line"><span class="keyword">print</span> response.getCode()</div><div class="line"><span class="comment">#读取内容</span></div><div class="line">cont = response.read()</div></pre></td></tr></table></figure>
<h2 id="urllib2-运行by-data-amp-http-header"><a href="#urllib2-运行by-data-amp-http-header" class="headerlink" title="urllib2 运行by data &amp; http header"></a>urllib2 运行by data &amp; http header</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="comment">#创建request对象</span></div><div class="line">request = urllib2.Request(url)</div><div class="line"><span class="comment">#添加数据</span></div><div class="line">request.add_data(<span class="string">'a'</span>,<span class="string">'1'</span>)</div><div class="line"><span class="comment">#添加http的header</span></div><div class="line">request.add_header(<span class="string">'User-Agent'</span>,<span class="string">'Mozilla/5.0'</span>)</div><div class="line"><span class="comment">#发送请求</span></div><div class="line">response = urllib2.urlopen(request)</div></pre></td></tr></table></figure>
<h2 id="添加特殊情景的处理器"><a href="#添加特殊情景的处理器" class="headerlink" title="添加特殊情景的处理器"></a>添加特殊情景的处理器</h2><ol>
<li>HTTPCookieProcessor</li>
<li>ProxyHandler</li>
<li>HTTPSHandler</li>
<li>HTTPRedirectHandler</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2,cookielib</div><div class="line"><span class="comment">#创建cookie容器</span></div><div class="line">cj = cookielib.CookieJar()</div><div class="line"><span class="comment"># 创建一个opener</span></div><div class="line">opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))</div><div class="line"><span class="comment">#给urllib2安装opener</span></div><div class="line">urllib2.install_opener(opener)</div><div class="line"><span class="comment">#使用带有cookie的urllib2访问网页</span></div><div class="line">response = urllib2.urlopen(<span class="string">"http://www.baidu.com"</span>)</div></pre></td></tr></table></figure>
<h1 id="网页解析器"><a href="#网页解析器" class="headerlink" title="网页解析器"></a>网页解析器</h1><p>用来提取有价值数据的工具</p>
<p>Python中</p>
<ol>
<li>正则表达式 （字符串形式的模糊匹配</li>
<li>html.parser 官网</li>
<li>Beautiful soup 兼容2和4</li>
<li>lxml</li>
</ol>
<p>2，3，4是结构化解析（DOM树</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip install beautifulsoup4</div><div class="line">#Install beautifulsoup4</div></pre></td></tr></table></figure>
<h2 id="Beatuiful-Soup"><a href="#Beatuiful-Soup" class="headerlink" title="Beatuiful Soup"></a>Beatuiful Soup</h2><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span> = <span class="string">'123.html'</span> <span class="attr">class</span>=<span class="string">'article_link'</span>&gt;</span>Python<span class="tag">&lt;/<span class="name">a</span>&gt;</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line">soup = BeautifulSoup(</div><div class="line">					html_doc, <span class="comment">#HTML文档字符串</span></div><div class="line">					<span class="string">'html.parser'</span> <span class="comment">#HTML解析器</span></div><div class="line">					from_encoding=<span class="string">'utf-8'</span> <span class="comment">#HTML文档的编码</span></div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="搜索节点"><a href="#搜索节点" class="headerlink" title="搜索节点"></a>搜索节点</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># soup.find_all(name,arrts,string)</span></div><div class="line"><span class="comment">#查找所有标签为a的节点</span></div><div class="line">soup.find_all(<span class="string">'a'</span>)</div><div class="line"><span class="comment">#查找所有标签为a，连接符合/view/123.htm形式的节点</span></div><div class="line">soup.find_all(<span class="string">'a'</span>,href=<span class="string">'/view/123.htm'</span>)</div><div class="line">soup.find_all(<span class="string">'a'</span>,href=re.compile(<span class="string">r'/view/\d+\.htm)) #使用正则表达式来匹配</span></div><div class="line">#查找所有标签为div，class为abc，文字为python的节点</div><div class="line">soup.find_all('div<span class="string">',class_='</span>abc<span class="string">',string="python")</span></div></pre></td></tr></table></figure>
<h1 id="开发实例爬虫"><a href="#开发实例爬虫" class="headerlink" title="开发实例爬虫"></a>开发实例爬虫</h1><p>确定目标 —&gt; 分析目标 —&gt; [url格式，数据格式，网页编码] —&gt; 编写代码 —&gt; 执行爬虫</p>
<h2 id="Main"><a href="#Main" class="headerlink" title="Main"></a>Main</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#crawler_main.py</span></div><div class="line"><span class="comment">#从这个package中import</span></div><div class="line"><span class="keyword">from</span> nameOfCurrentPackage <span class="keyword">import</span> url_manager,html_downloader,html_parser,html_outputer</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrawlerMain</span><span class="params">(object)</span>:</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.urls = url_manager.UrlManager()</div><div class="line">        self.downloader = html_downloader.HtmlDownloader()</div><div class="line">        self.parser = html_parser.HtmlParser()</div><div class="line">        self.outputer - html_outputer.HtmlOutputer()</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">craw</span><span class="params">(self, root_url)</span>:</span></div><div class="line">        count = <span class="number">1</span></div><div class="line">        self.urls.add_new_url(root_url)</div><div class="line">        <span class="keyword">while</span> self.urls.has_new_url():</div><div class="line">            <span class="keyword">try</span>:</div><div class="line">            	new_url = self.urls.get_new_url()</div><div class="line">            	<span class="keyword">print</span> <span class="string">'craw %d : %s'</span> %(count,new_url)</div><div class="line">            	html_cont = self.downloader.download(new_url)</div><div class="line">            	new_urls, new_data = self.parser.parse(newurl,html_cont)</div><div class="line">           		self.urls.add_new_urls(new_urls)  <span class="comment">#补充新的url</span></div><div class="line">            	self.outputer.collect_data(new_data)</div><div class="line">            	count = count + <span class="number">1</span></div><div class="line">            <span class="keyword">except</span>:</div><div class="line">                <span class="keyword">print</span> <span class="string">'craw failed'</span></div><div class="line">        self.outputer.output_html()</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    root_url = <span class="string">"http://...."</span></div><div class="line">    obj_crawler = CrawlerMain()</div><div class="line">    obj_crawler.craw(root_url)</div></pre></td></tr></table></figure>
<h2 id="UrlManager"><a href="#UrlManager" class="headerlink" title="UrlManager"></a>UrlManager</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UrlManager</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.new_urls = set()</div><div class="line">        self.old_urls = set()</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_url</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.newurls <span class="keyword">and</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.old_urls:</div><div class="line">        	self.new_urls.add(url)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_urls</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">if</span> urls <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> len(urls) == <span class="number">0</span>:</div><div class="line">        	<span class="keyword">return</span></div><div class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</div><div class="line">            self.add_new_url(url)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_new_url</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> len(self.new_urls) != <span class="number">0</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_new_url</span><span class="params">(self)</span>:</span></div><div class="line">        new_url = self.new_urls.pop()</div><div class="line">        self.old_urls.add(new_url)</div><div class="line">        <span class="keyword">return</span> new_url</div></pre></td></tr></table></figure>
<h2 id="HtmlDownloader"><a href="#HtmlDownloader" class="headerlink" title="HtmlDownloader"></a>HtmlDownloader</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlDownloader</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self, url)</span>:</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> none:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line">        response = urllib2.urlopen(url)</div><div class="line">        <span class="keyword">if</span> response.getCode() != <span class="number">200</span>:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line">        <span class="keyword">return</span> response.read()</div></pre></td></tr></table></figure>
<h2 id="HtmlParser"><a href="#HtmlParser" class="headerlink" title="HtmlParser"></a>HtmlParser</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlParser</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_new_urls</span><span class="params">(self,page_url,soup)</span>:</span></div><div class="line">        new_urls = set()</div><div class="line">        links = soup.find_all(<span class="string">'a'</span>, href=re.compile(<span class="string">r"///////"</span>))</div><div class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</div><div class="line">            new_url = link[<span class="string">"href"</span>]</div><div class="line">            <span class="comment"># 拼接url</span></div><div class="line">            new_full_url = urlparse.urljoin(page_url, new_url)</div><div class="line">            new_urls.add(new_full_url)</div><div class="line">        <span class="keyword">return</span> new_urls</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_new_data</span><span class="params">(self, page_url, soup)</span>:</span></div><div class="line">        res_data = &#123;&#125;</div><div class="line">        res_data[<span class="string">'url'</span>] = page_url</div><div class="line">        title_node = soup.find(<span class="string">'标签'</span>, class_=<span class="string">''</span>).find(<span class="string">"h1"</span>)</div><div class="line">        res_data[<span class="string">'title'</span>] = title_node.get_text()</div><div class="line">        summary_node = soup.find(..........)</div><div class="line">        res_data[<span class="string">'summary'</span>] = summary_node.get_text()</div><div class="line">        <span class="keyword">return</span> res_data</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, page_url, html_cont)</span>:</span></div><div class="line">    <span class="keyword">if</span> page_url <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> html_cont <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        <span class="keyword">return</span> </div><div class="line">    soup = BeautifulSoup(html_cont, <span class="string">'html.parser'</span>, from_encoding=<span class="string">'utf-8'</span>)</div><div class="line">    new_urls = self._get_new_urls(page_url,soup)</div><div class="line">    new_data = self._get_new_data(page_url,soup)</div><div class="line">    <span class="keyword">return</span> new_urls, new_data</div></pre></td></tr></table></figure>
<h2 id="HtmlOutputer"><a href="#HtmlOutputer" class="headerlink" title="HtmlOutputer"></a>HtmlOutputer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlOutputer</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.data = []</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">collect_data</span><span class="params">(self,data)</span>:</span></div><div class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        self.data.append(data)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output_html</span><span class="params">(self)</span>:</span></div><div class="line">        fout = open(<span class="string">'output.html'</span>,<span class="string">'w'</span>) <span class="comment">#w为“写模式”</span></div><div class="line">        fout.write(<span class="string">"&lt;html&gt;"</span>)</div><div class="line">        fout.write(<span class="string">"&lt;body&gt;"</span>)</div><div class="line">        fout.write(<span class="string">"&lt;table&gt;"</span>)</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> self.data:</div><div class="line">            fout.write(<span class="string">"&lt;tr&gt;"</span>)</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'url'</span>])</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'title'</span>].encode(<span class="string">'utf-8'</span>))</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'summary'</span>].encode(<span class="string">'utf-8'</span>))</div><div class="line">            fout.write(<span class="string">"&lt;/tr&gt;"</span>)</div><div class="line">        fout.write(<span class="string">"&lt;/html&gt;"</span>)</div><div class="line">        fout.write(<span class="string">"&lt;/body&gt;"</span>)</div><div class="line">        fout.write(<span class="string">"&lt;/table&gt;"</span>)</div></pre></td></tr></table></figure>

    </section>
    <footer class="post-footer">
      <section class="author">
    <h4>Jason Jiang</h4>
    <p>一名苦逼的cs学生</p>
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" href="http://twitter.com/share?url=http://jxdashabi.com/2017/05/27/crawler/"
       onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://jxdashabi.com/2017/05/27/crawler/"
       onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=http://jxdashabi.com/2017/05/27/crawler/"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>
    </footer>
  </article>
  <nav class="pagination" role="pagination">
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2017/05/24/javascript-note/">
        JavaScript笔记 →
    </a>
    
</nav>
  <div id="comment" class="comments-area">
    <h1 class="title"><a href="#disqus_comments" name="disqus_comments">Comments</a></h1>

    
</div>
</main>


  
<footer class="site-footer">
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">Jason's Blog</a> &copy; 2014 &bull; All rights reserved.</section>
     <section class="poweredby">Proudly published with <a class="icon-ghost" href="http://zespia.tw/hexo/">Hexo</a></section>
  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>






</body>
</html>
